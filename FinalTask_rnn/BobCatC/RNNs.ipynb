{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "RNNs.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dgbkwH3WkW1O",
        "colab_type": "text"
      },
      "source": [
        "# Задание 6: Рекуррентные нейронные сети (RNNs)\n",
        "\n",
        "Это задание адаптиповано из Deep NLP Course at ABBYY (https://github.com/DanAnastasyev/DeepNLP-Course) с разрешения автора - Даниила Анастасьева. Спасибо ему огромное!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "P59NYU98GCb9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "outputId": "8028b01f-889e-4267-ff99-488e151c4987"
      },
      "source": [
        "!pip3 -qq install torch==1.4.0\n",
        "!pip3 -qq install bokeh==2.0.0\n",
        "!pip3 -qq install gensim==3.8.1\n",
        "!pip3 -qq install nltk\n",
        "!pip3 -qq install scikit-learn==0.20.2"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-553c784b6e7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip3 -qq install torch==1.4.0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip3 -qq install bokeh==2.0.0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip3 -qq install gensim==3.8.1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip3 -qq install nltk'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip3 -qq install scikit-learn==0.20.2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_shell.py\u001b[0m in \u001b[0;36msystem\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m       \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'also_return_output'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_system_commands\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_system_compat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint:disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpip_warn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_system_compat\u001b[0;34m(shell, cmd, also_return_output)\u001b[0m\n\u001b[1;32m    436\u001b[0m   \u001b[0;31m# stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m   result = _run_command(\n\u001b[0;32m--> 438\u001b[0;31m       shell.var_expand(cmd, depth=2), clear_streamed_output=False)\n\u001b[0m\u001b[1;32m    439\u001b[0m   \u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_ns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'_exit_code'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_INTERRUPTED_SIGNALS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_run_command\u001b[0;34m(cmd, clear_streamed_output)\u001b[0m\n\u001b[1;32m    193\u001b[0m       \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild_pty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0m_monitor_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent_pty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoll\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdate_stdin_widget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0mepoll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_display_stdin_widget\u001b[0;34m(delay_millis)\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m   \u001b[0mhide_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'cell_remove_stdin'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m   \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocking_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mhide_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent_header\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    169\u001b[0m   \u001b[0;31m# unique.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m   \u001b[0mrequest_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msend_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     if (reply.get('type') == 'colab_reply' and\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8sVtGHmA9aBM",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    from torch.cuda import FloatTensor, LongTensor\n",
        "else:\n",
        "    print(\"Warning: no CUDA found\")\n",
        "    from torch import FloatTensor, LongTensor\n",
        "\n",
        "np.random.seed(42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-6CNKM3b4hT1"
      },
      "source": [
        "# Рекуррентные нейронные сети (RNNs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "O_XkoGNQUeGm"
      },
      "source": [
        "## POS Tagging"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QFEtWrS_4rUs"
      },
      "source": [
        "Мы рассмотрим применение рекуррентных сетей к задаче sequence labeling (последняя картинка).\n",
        "\n",
        "![RNN types](http://karpathy.github.io/assets/rnn/diags.jpeg)\n",
        "\n",
        "*From [The Unreasonable Effectiveness of Recurrent Neural Networks](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)*\n",
        "\n",
        "Самые популярные примеры для такой постановки задачи - Part-of-Speech Tagging и Named Entity Recognition.\n",
        "\n",
        "Мы порешаем сейчас POS Tagging для английского.\n",
        "\n",
        "Будем работать с таким набором тегов:\n",
        "- ADJ - adjective (new, good, high, ...)\n",
        "- ADP - adposition (on, of, at, ...)\n",
        "- ADV - adverb (really, already, still, ...)\n",
        "- CONJ - conjunction (and, or, but, ...)\n",
        "- DET - determiner, article (the, a, some, ...)\n",
        "- NOUN - noun (year, home, costs, ...)\n",
        "- NUM - numeral (twenty-four, fourth, 1991, ...)\n",
        "- PRT - particle (at, on, out, ...)\n",
        "- PRON - pronoun (he, their, her, ...)\n",
        "- VERB - verb (is, say, told, ...)\n",
        "- . - punctuation marks (. , ;)\n",
        "- X - other (ersatz, esprit, dunno, ...)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "EPIkKdFlHB-X"
      },
      "source": [
        "Скачаем данные:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TiA2dGmgF1rW",
        "outputId": "7decf04a-7561-4337-b6ac-d13baf598652",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "import nltk\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "nltk.download('brown')\n",
        "nltk.download('universal_tagset')\n",
        "\n",
        "data = nltk.corpus.brown.tagged_sents(tagset='universal')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n",
            "[nltk_data] Downloading package universal_tagset to /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/universal_tagset.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "d93g_swyJA_V"
      },
      "source": [
        "Пример размеченного предложения:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QstS4NO0L97c",
        "outputId": "ea05b1cf-ff78-4779-e0ea-cc20857eb62d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        }
      },
      "source": [
        "for word, tag in data[0]:\n",
        "    print('{:15}\\t{}'.format(word, tag))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The            \tDET\n",
            "Fulton         \tNOUN\n",
            "County         \tNOUN\n",
            "Grand          \tADJ\n",
            "Jury           \tNOUN\n",
            "said           \tVERB\n",
            "Friday         \tNOUN\n",
            "an             \tDET\n",
            "investigation  \tNOUN\n",
            "of             \tADP\n",
            "Atlanta's      \tNOUN\n",
            "recent         \tADJ\n",
            "primary        \tNOUN\n",
            "election       \tNOUN\n",
            "produced       \tVERB\n",
            "``             \t.\n",
            "no             \tDET\n",
            "evidence       \tNOUN\n",
            "''             \t.\n",
            "that           \tADP\n",
            "any            \tDET\n",
            "irregularities \tNOUN\n",
            "took           \tVERB\n",
            "place          \tNOUN\n",
            ".              \t.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "epdW8u_YXcAv"
      },
      "source": [
        "Построим разбиение на train/val/test - наконец-то, всё как у нормальных людей.\n",
        "\n",
        "На train будем учиться, по val - подбирать параметры и делать всякие early stopping, а на test - принимать модель по ее финальному качеству."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xTai8Ta0lgwL",
        "outputId": "76c9f9bb-b520-49e8-f143-eba4e00469cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "train_data, test_data = train_test_split(data, test_size=0.25, random_state=42)\n",
        "train_data, val_data = train_test_split(train_data, test_size=0.15, random_state=42)\n",
        "\n",
        "print('Words count in train set:', sum(len(sent) for sent in train_data))\n",
        "print('Words count in val set:', sum(len(sent) for sent in val_data))\n",
        "print('Words count in test set:', sum(len(sent) for sent in test_data))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Words count in train set: 739769\n",
            "Words count in val set: 130954\n",
            "Words count in test set: 290469\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "eChdLNGtXyP0"
      },
      "source": [
        "Построим маппинги из слов в индекс и из тега в индекс:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pCjwwDs6Zq9x",
        "outputId": "1e59094a-df3b-4a5f-d1ef-fa8f77848293",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "words = {word for sample in train_data for word, tag in sample}\n",
        "word2ind = {word: ind + 1 for ind, word in enumerate(words)}\n",
        "word2ind['<pad>'] = 0\n",
        "\n",
        "tags = {tag for sample in train_data for word, tag in sample}\n",
        "tag2ind = {tag: ind + 1 for ind, tag in enumerate(tags)}\n",
        "tag2ind['<pad>'] = 0\n",
        "\n",
        "print('Unique words in train = {}. Tags = {}'.format(len(word2ind), tags))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unique words in train = 45441. Tags = {'PRON', 'PRT', 'CONJ', 'X', 'ADV', 'NOUN', 'DET', '.', 'ADJ', 'VERB', 'NUM', 'ADP'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "URC1B2nvPGFt",
        "outputId": "d1e40682-a1cc-45fd-e1a5-562a6b4e1551",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "tag_distribution = Counter(tag for sample in train_data for _, tag in sample)\n",
        "tag_distribution = [tag_distribution[tag] for tag in tags]\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "\n",
        "bar_width = 0.35\n",
        "plt.bar(np.arange(len(tags)), tag_distribution, bar_width, align='center', alpha=0.5)\n",
        "plt.xticks(np.arange(len(tags)), tags)\n",
        "    \n",
        "plt.show()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmkAAAEvCAYAAAAemFY+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gArQwbzWWkgi"
      },
      "source": [
        "## Бейзлайн\n",
        "\n",
        "Какой самый простой теггер можно придумать? Давайте просто запоминать, какие теги самые вероятные для слова (или для последовательности):\n",
        "\n",
        "![tag-context](https://www.nltk.org/images/tag-context.png)  \n",
        "*From [Categorizing and Tagging Words, nltk](https://www.nltk.org/book/ch05.html)*\n",
        "\n",
        "На картинке показано, что для предсказания $t_n$ используются два предыдущих предсказанных тега + текущее слово. По корпусу считаются вероятность для $P(t_n| w_n, t_{n-1}, t_{n-2})$, выбирается тег с максимальной вероятностью.\n",
        "\n",
        "Более аккуратно такая идея реализована в Hidden Markov Models: по тренировочному корпусу вычисляются вероятности $P(w_n| t_n), P(t_n|t_{n-1}, t_{n-2})$ и максимизируется их произведение.\n",
        "\n",
        "Простейший вариант - униграммная модель, учитывающая только слово:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5rWmSToIaeAo",
        "outputId": "d8529b4c-4a9b-4078-9463-a5f041c0085d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import nltk\n",
        "\n",
        "default_tagger = nltk.DefaultTagger('NN')\n",
        "\n",
        "unigram_tagger = nltk.UnigramTagger(train_data, backoff=default_tagger)\n",
        "print('Accuracy of unigram tagger = {:.2%}'.format(unigram_tagger.evaluate(test_data)))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of unigram tagger = 92.62%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "07Ymb_MkbWsF"
      },
      "source": [
        "Добавим вероятности переходов:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vjz_Rk0bbMyH",
        "outputId": "c89ff67b-8d6a-4051-d12c-a1a754e70fec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "bigram_tagger = nltk.BigramTagger(train_data, backoff=unigram_tagger)\n",
        "print('Accuracy of bigram tagger = {:.2%}'.format(bigram_tagger.evaluate(test_data)))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of bigram tagger = 93.42%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uWMw6QHvbaDd"
      },
      "source": [
        "Обратите внимание, что `backoff` важен:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8XCuxEBVbOY_",
        "outputId": "c6fa1704-bd7e-41a3-e299-3ae515f9869f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "trigram_tagger = nltk.TrigramTagger(train_data)\n",
        "print('Accuracy of trigram tagger = {:.2%}'.format(trigram_tagger.evaluate(test_data)))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of trigram tagger = 23.33%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4t3xyYd__8d-"
      },
      "source": [
        "## Увеличиваем контекст с рекуррентными сетями\n",
        "\n",
        "Униграмная модель работает на удивление хорошо, но мы же собрались учить сеточки.\n",
        "\n",
        "Омонимия - основная причина, почему униграмная модель плоха:  \n",
        "*“he cashed a check at the **bank**”*  \n",
        "vs  \n",
        "*“he sat on the **bank** of the river”*\n",
        "\n",
        "Поэтому нам очень полезно учитывать контекст при предсказании тега.\n",
        "\n",
        "Воспользуемся LSTM - он умеет работать с контекстом очень даже хорошо:\n",
        "\n",
        "![](https://image.ibb.co/kgmoff/Baseline-Tagger.png)\n",
        "\n",
        "Синим показано выделение фичей из слова, LSTM оранжевенький - он строит эмбеддинги слов с учетом контекста, а дальше зелененькая логистическая регрессия делает предсказания тегов."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RtRbz1SwgEqc",
        "colab": {}
      },
      "source": [
        "def convert_data(data, word2ind, tag2ind):\n",
        "    X = [[word2ind.get(word, 0) for word, _ in sample] for sample in data]\n",
        "    y = [[tag2ind[tag] for _, tag in sample] for sample in data]\n",
        "    \n",
        "    return X, y\n",
        "\n",
        "X_train, y_train = convert_data(train_data, word2ind, tag2ind)\n",
        "X_val, y_val = convert_data(val_data, word2ind, tag2ind)\n",
        "X_test, y_test = convert_data(test_data, word2ind, tag2ind)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DhsTKZalfih6",
        "colab": {}
      },
      "source": [
        "def iterate_batches(data, batch_size):\n",
        "    X, y = data\n",
        "    n_samples = len(X)\n",
        "\n",
        "    indices = np.arange(n_samples)\n",
        "    np.random.shuffle(indices)\n",
        "    \n",
        "    for start in range(0, n_samples, batch_size):\n",
        "        end = min(start + batch_size, n_samples)\n",
        "        \n",
        "        batch_indices = indices[start:end]\n",
        "        \n",
        "        max_sent_len = max(len(X[ind]) for ind in batch_indices)\n",
        "        X_batch = np.zeros((len(batch_indices), max_sent_len))\n",
        "        y_batch = np.zeros((len(batch_indices), max_sent_len))\n",
        "\n",
        "        for batch_ind, sample_ind in enumerate(batch_indices):\n",
        "            X_batch[batch_ind, :len(X[sample_ind])] = X[sample_ind]\n",
        "            y_batch[batch_ind, :len(y[sample_ind])] = y[sample_ind]\n",
        "            \n",
        "        yield X_batch, y_batch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "l4XsRII5kW5x",
        "outputId": "916f3cf2-fb54-4f3b-93a5-2e830734696a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_batch, y_batch = next(iterate_batches((X_train, y_train), 4))\n",
        "\n",
        "X_batch.shape, y_batch.shape"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((32, 4), (32, 4))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "C5I9E9P6eFYv"
      },
      "source": [
        "**Задание** Реализуйте `LSTMTagger`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WVEHju54d68T",
        "colab": {}
      },
      "source": [
        "class LSTMTagger(nn.Module):\n",
        "    def __init__(self, vocab_size, tagset_size, word_emb_dim=100, lstm_hidden_dim=128, lstm_layers_count=1):\n",
        "        super().__init__()\n",
        "        \n",
        "        \n",
        "        self.embedding = nn.Embedding(vocab_size, word_emb_dim)\n",
        "        self.lstm = nn.LSTM(word_emb_dim, lstm_hidden_dim, num_layers=lstm_layers_count)\n",
        "        self.fc = nn.Linear(lstm_hidden_dim, tagset_size)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        result = self.embedding.forward(inputs)\n",
        "        result, _ = self.lstm.forward(result)\n",
        "        result = self.fc.forward(result)\n",
        "        return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "q_HA8zyheYGH"
      },
      "source": [
        "**Задание** Научитесь считать accuracy и loss (а заодно проверьте, что модель работает)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jbrxsZ2mehWB",
        "colab": {}
      },
      "source": [
        "lstm_tagger = LSTMTagger(\n",
        "    vocab_size=len(word2ind),\n",
        "    tagset_size=len(tag2ind)\n",
        ").cuda()\n",
        "\n",
        "X_batch, y_batch = LongTensor(X_batch), LongTensor(y_batch)\n",
        "\n",
        "logits = lstm_tagger(X_batch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0Ymx6gMvnbO",
        "colab_type": "code",
        "outputId": "d6456a93-6f4d-4679-8c7c-18ed76644209",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def calc_accuracy(logits, y_batch):\n",
        "    predictions = torch.argmax(logits, dim=-1)\n",
        "    correct = ((predictions == y_batch) * (y_batch != 0)).sum().item()\n",
        "    total = (y_batch != 0).sum().item()\n",
        "    return correct, total\n",
        "\n",
        "correct, total = calc_accuracy(logits, y_batch)\n",
        "accuracy = correct / total\n",
        "print(\"Untrained model's accuracy = {:4.2f}%\".format(accuracy * 100))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Untrained model's accuracy = 8.70%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nSgV3NPUpcjH"
      },
      "source": [
        "**Задание** Вставьте эти вычисление в функцию:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FprPQ0gllo7b",
        "colab": {}
      },
      "source": [
        "import math\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "def do_epoch(model, criterion, data, batch_size, optimizer=None, name=None):\n",
        "    epoch_loss = 0\n",
        "    correct_count = 0\n",
        "    sum_count = 0\n",
        "    \n",
        "    is_train = not optimizer is None\n",
        "    name = name or ''\n",
        "    model.train(is_train)\n",
        "    \n",
        "    batches_count = math.ceil(len(data[0]) / batch_size)\n",
        "    \n",
        "    with torch.autograd.set_grad_enabled(is_train):\n",
        "        with tqdm(total=batches_count) as progress_bar:\n",
        "            for i, (X_batch, y_batch) in enumerate(iterate_batches(data, batch_size)):\n",
        "                X_batch, y_batch = LongTensor(X_batch), LongTensor(y_batch)\n",
        "                logits = model(X_batch)\n",
        "\n",
        "                loss = criterion(logits.view(-1, logits.shape[-1]), y_batch.view(-1))\n",
        "\n",
        "                epoch_loss += loss.item()\n",
        "\n",
        "                if optimizer:\n",
        "                    optimizer.zero_grad()\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "\n",
        "                cur_correct_count, cur_sum_count = calc_accuracy(logits, y_batch)\n",
        "\n",
        "                correct_count += cur_correct_count\n",
        "                sum_count += cur_sum_count\n",
        "\n",
        "                progress_bar.update()\n",
        "                progress_bar.set_description('{:>5s} Loss = {:.5f}, Accuracy = {:.2%}'.format(\n",
        "                    name, loss.item(), cur_correct_count / cur_sum_count)\n",
        "                )\n",
        "                \n",
        "            progress_bar.set_description('{:>5s} Loss = {:.5f}, Accuracy = {:.2%}'.format(\n",
        "                name, epoch_loss / batches_count, correct_count / sum_count)\n",
        "            )\n",
        "\n",
        "    return epoch_loss / batches_count, correct_count / sum_count\n",
        "\n",
        "\n",
        "def fit(model, criterion, optimizer, train_data, epochs_count=1, batch_size=32,\n",
        "        val_data=None, val_batch_size=None):\n",
        "        \n",
        "    if not val_data is None and val_batch_size is None:\n",
        "        val_batch_size = batch_size\n",
        "        \n",
        "    for epoch in range(epochs_count):\n",
        "        name_prefix = '[{} / {}] '.format(epoch + 1, epochs_count)\n",
        "        train_loss, train_acc = do_epoch(model, criterion, train_data, batch_size, optimizer, name_prefix + 'Train:')\n",
        "        \n",
        "        if not val_data is None:\n",
        "            val_loss, val_acc = do_epoch(model, criterion, val_data, val_batch_size, None, name_prefix + '  Val:')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Pqfbeh1ltEYa",
        "outputId": "1fed9d58-cf91-42d6-9370-803e117670ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        }
      },
      "source": [
        "lstm_tagger = LSTMTagger(\n",
        "    vocab_size=len(word2ind),\n",
        "    tagset_size=len(tag2ind)\n",
        ").cuda()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss().cuda()\n",
        "optimizer = optim.Adam(lstm_tagger.parameters())\n",
        "\n",
        "fit(lstm_tagger, criterion, optimizer, train_data=(X_train, y_train), epochs_count=20,\n",
        "    batch_size=64, val_data=(X_val, y_val), val_batch_size=512)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 / 20] Train: Loss = 0.31259, Accuracy = 72.55%: 100%|██████████| 572/572 [00:04<00:00, 126.65it/s]\n",
            "[1 / 20]   Val: Loss = 0.10562, Accuracy = 84.49%: 100%|██████████| 13/13 [00:00<00:00, 83.60it/s]\n",
            "[2 / 20] Train: Loss = 0.09962, Accuracy = 89.91%: 100%|██████████| 572/572 [00:04<00:00, 124.20it/s]\n",
            "[2 / 20]   Val: Loss = 0.07680, Accuracy = 89.16%: 100%|██████████| 13/13 [00:00<00:00, 85.61it/s]\n",
            "[3 / 20] Train: Loss = 0.06781, Accuracy = 93.15%: 100%|██████████| 572/572 [00:04<00:00, 128.32it/s]\n",
            "[3 / 20]   Val: Loss = 0.07201, Accuracy = 90.81%: 100%|██████████| 13/13 [00:00<00:00, 82.77it/s]\n",
            "[4 / 20] Train: Loss = 0.05099, Accuracy = 94.82%: 100%|██████████| 572/572 [00:04<00:00, 127.01it/s]\n",
            "[4 / 20]   Val: Loss = 0.07013, Accuracy = 91.65%: 100%|██████████| 13/13 [00:00<00:00, 87.65it/s]\n",
            "[5 / 20] Train: Loss = 0.04092, Accuracy = 95.81%: 100%|██████████| 572/572 [00:04<00:00, 128.21it/s]\n",
            "[5 / 20]   Val: Loss = 0.06919, Accuracy = 92.26%: 100%|██████████| 13/13 [00:00<00:00, 88.72it/s]\n",
            "[6 / 20] Train: Loss = 0.03333, Accuracy = 96.57%: 100%|██████████| 572/572 [00:04<00:00, 128.45it/s]\n",
            "[6 / 20]   Val: Loss = 0.06853, Accuracy = 92.53%: 100%|██████████| 13/13 [00:00<00:00, 88.14it/s]\n",
            "[7 / 20] Train: Loss = 0.02752, Accuracy = 97.11%: 100%|██████████| 572/572 [00:04<00:00, 132.33it/s]\n",
            "[7 / 20]   Val: Loss = 0.06852, Accuracy = 92.82%: 100%|██████████| 13/13 [00:00<00:00, 89.75it/s]\n",
            "[8 / 20] Train: Loss = 0.02309, Accuracy = 97.59%: 100%|██████████| 572/572 [00:04<00:00, 132.37it/s]\n",
            "[8 / 20]   Val: Loss = 0.06715, Accuracy = 92.86%: 100%|██████████| 13/13 [00:00<00:00, 85.93it/s]\n",
            "[9 / 20] Train: Loss = 0.01911, Accuracy = 97.99%: 100%|██████████| 572/572 [00:04<00:00, 131.68it/s]\n",
            "[9 / 20]   Val: Loss = 0.07147, Accuracy = 92.90%: 100%|██████████| 13/13 [00:00<00:00, 88.58it/s]\n",
            "[10 / 20] Train: Loss = 0.01603, Accuracy = 98.31%: 100%|██████████| 572/572 [00:04<00:00, 129.15it/s]\n",
            "[10 / 20]   Val: Loss = 0.07161, Accuracy = 92.83%: 100%|██████████| 13/13 [00:00<00:00, 87.67it/s]\n",
            "[11 / 20] Train: Loss = 0.01338, Accuracy = 98.61%: 100%|██████████| 572/572 [00:04<00:00, 127.33it/s]\n",
            "[11 / 20]   Val: Loss = 0.07221, Accuracy = 92.82%: 100%|██████████| 13/13 [00:00<00:00, 84.06it/s]\n",
            "[12 / 20] Train: Loss = 0.01106, Accuracy = 98.85%: 100%|██████████| 572/572 [00:04<00:00, 126.11it/s]\n",
            "[12 / 20]   Val: Loss = 0.08256, Accuracy = 92.78%: 100%|██████████| 13/13 [00:00<00:00, 89.62it/s]\n",
            "[13 / 20] Train: Loss = 0.00925, Accuracy = 99.07%: 100%|██████████| 572/572 [00:04<00:00, 128.42it/s]\n",
            "[13 / 20]   Val: Loss = 0.07691, Accuracy = 92.68%: 100%|██████████| 13/13 [00:00<00:00, 84.17it/s]\n",
            "[14 / 20] Train: Loss = 0.00765, Accuracy = 99.26%: 100%|██████████| 572/572 [00:04<00:00, 130.73it/s]\n",
            "[14 / 20]   Val: Loss = 0.08760, Accuracy = 92.55%: 100%|██████████| 13/13 [00:00<00:00, 87.22it/s]\n",
            "[15 / 20] Train: Loss = 0.00616, Accuracy = 99.41%: 100%|██████████| 572/572 [00:04<00:00, 126.07it/s]\n",
            "[15 / 20]   Val: Loss = 0.09230, Accuracy = 92.55%: 100%|██████████| 13/13 [00:00<00:00, 87.20it/s]\n",
            "[16 / 20] Train: Loss = 0.00496, Accuracy = 99.53%: 100%|██████████| 572/572 [00:04<00:00, 132.39it/s]\n",
            "[16 / 20]   Val: Loss = 0.08913, Accuracy = 92.51%: 100%|██████████| 13/13 [00:00<00:00, 87.24it/s]\n",
            "[17 / 20] Train: Loss = 0.00417, Accuracy = 99.62%: 100%|██████████| 572/572 [00:04<00:00, 129.74it/s]\n",
            "[17 / 20]   Val: Loss = 0.09864, Accuracy = 92.55%: 100%|██████████| 13/13 [00:00<00:00, 85.04it/s]\n",
            "[18 / 20] Train: Loss = 0.00339, Accuracy = 99.70%: 100%|██████████| 572/572 [00:04<00:00, 128.10it/s]\n",
            "[18 / 20]   Val: Loss = 0.09444, Accuracy = 92.49%: 100%|██████████| 13/13 [00:00<00:00, 84.37it/s]\n",
            "[19 / 20] Train: Loss = 0.00285, Accuracy = 99.75%: 100%|██████████| 572/572 [00:04<00:00, 127.83it/s]\n",
            "[19 / 20]   Val: Loss = 0.09658, Accuracy = 92.54%: 100%|██████████| 13/13 [00:00<00:00, 81.96it/s]\n",
            "[20 / 20] Train: Loss = 0.00250, Accuracy = 99.77%: 100%|██████████| 572/572 [00:04<00:00, 131.97it/s]\n",
            "[20 / 20]   Val: Loss = 0.10868, Accuracy = 92.50%: 100%|██████████| 13/13 [00:00<00:00, 91.22it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "m0qGetIhfUE5"
      },
      "source": [
        "### Masking\n",
        "\n",
        "**Задание** Проверьте себя - не считаете ли вы потери и accuracy на паддингах - очень легко получить высокое качество за счет этого.\n",
        "\n",
        "У функции потерь есть параметр `ignore_index`, для таких целей. Для accuracy нужно использовать маскинг - умножение на маску из нулей и единиц, где нули на позициях паддингов (а потом усреднение по ненулевым позициям в маске)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nAfV2dEOfHo5"
      },
      "source": [
        "**Задание** Посчитайте качество модели на тесте. Ожидается результат лучше бейзлайна!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "98wr38_rw55D",
        "outputId": "c7d194ec-c9dc-4100-e760-025c06978517",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "_ = do_epoch(lstm_tagger, criterion, (X_test, y_test), 64, None, 'Test:')"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test: Loss = 0.16287, Accuracy = 92.58%: 100%|██████████| 224/224 [00:00<00:00, 269.12it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PXUTSFaEHbDG"
      },
      "source": [
        "### Bidirectional LSTM\n",
        "\n",
        "Благодаря BiLSTM можно использовать сразу оба контеста при предсказании тега слова. Т.е. для каждого токена $w_i$ forward LSTM будет выдавать представление $\\mathbf{f_i} \\sim (w_1, \\ldots, w_i)$ - построенное по всему левому контексту - и $\\mathbf{b_i} \\sim (w_n, \\ldots, w_i)$ - представление правого контекста. Их конкатенация автоматически захватит весь доступный контекст слова: $\\mathbf{h_i} = [\\mathbf{f_i}, \\mathbf{b_i}] \\sim (w_1, \\ldots, w_n)$.\n",
        "\n",
        "![BiLSTM](https://www.researchgate.net/profile/Wang_Ling/publication/280912217/figure/fig2/AS:391505383575555@1470353565299/Illustration-of-our-neural-network-for-POS-tagging.png)  \n",
        "*From [Finding Function in Form: Compositional Character Models for Open Vocabulary Word Representation](https://arxiv.org/abs/1508.02096)*\n",
        "\n",
        "**Задание** Добавьте Bidirectional LSTM."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndZtMB4nkW2R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BiLSTMTagger(nn.Module):\n",
        "    def __init__(self, vocab_size, tagset_size, word_emb_dim=100, lstm_hidden_dim=128, lstm_layers_count=1):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.embedding = nn.Embedding(vocab_size, word_emb_dim)\n",
        "        self.lstm = nn.LSTM(word_emb_dim, lstm_hidden_dim, num_layers=lstm_layers_count, bidirectional=True)\n",
        "        self.fc = nn.Linear(2 * lstm_hidden_dim, tagset_size)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        result = self.embedding.forward(inputs)\n",
        "        result, _ = self.lstm.forward(result)\n",
        "        result = self.fc.forward(result)\n",
        "        return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iGeGP-x83xP7",
        "colab_type": "code",
        "outputId": "c12259d5-2702-4d17-ba49-94035756b69e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "bilstm_tagger = BiLSTMTagger(\n",
        "    vocab_size=len(word2ind),\n",
        "    tagset_size=len(tag2ind)\n",
        ").cuda()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss().cuda()\n",
        "optimizer = optim.Adam(bilstm_tagger.parameters())\n",
        "\n",
        "fit(bilstm_tagger, criterion, optimizer, train_data=(X_train, y_train), epochs_count=25,\n",
        "    batch_size=64, val_data=(X_val, y_val), val_batch_size=512)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 / 30] Train: Loss = 0.25416, Accuracy = 76.71%: 100%|██████████| 572/572 [00:05<00:00, 104.70it/s]\n",
            "[1 / 30]   Val: Loss = 0.07478, Accuracy = 89.90%: 100%|██████████| 13/13 [00:00<00:00, 68.62it/s]\n",
            "[2 / 30] Train: Loss = 0.07516, Accuracy = 92.69%: 100%|██████████| 572/572 [00:05<00:00, 101.50it/s]\n",
            "[2 / 30]   Val: Loss = 0.05434, Accuracy = 93.66%: 100%|██████████| 13/13 [00:00<00:00, 74.64it/s]\n",
            "[3 / 30] Train: Loss = 0.04851, Accuracy = 95.39%: 100%|██████████| 572/572 [00:05<00:00, 103.20it/s]\n",
            "[3 / 30]   Val: Loss = 0.04054, Accuracy = 94.89%: 100%|██████████| 13/13 [00:00<00:00, 70.36it/s]\n",
            "[4 / 30] Train: Loss = 0.03473, Accuracy = 96.78%: 100%|██████████| 572/572 [00:05<00:00, 103.02it/s]\n",
            "[4 / 30]   Val: Loss = 0.03763, Accuracy = 95.47%: 100%|██████████| 13/13 [00:00<00:00, 70.31it/s]\n",
            "[5 / 30] Train: Loss = 0.02532, Accuracy = 97.66%: 100%|██████████| 572/572 [00:05<00:00, 106.36it/s]\n",
            "[5 / 30]   Val: Loss = 0.03783, Accuracy = 95.85%: 100%|██████████| 13/13 [00:00<00:00, 74.02it/s]\n",
            "[6 / 30] Train: Loss = 0.01886, Accuracy = 98.29%: 100%|██████████| 572/572 [00:05<00:00, 107.67it/s]\n",
            "[6 / 30]   Val: Loss = 0.03637, Accuracy = 96.07%: 100%|██████████| 13/13 [00:00<00:00, 70.29it/s]\n",
            "[7 / 30] Train: Loss = 0.01363, Accuracy = 98.78%: 100%|██████████| 572/572 [00:05<00:00, 105.99it/s]\n",
            "[7 / 30]   Val: Loss = 0.03835, Accuracy = 96.16%: 100%|██████████| 13/13 [00:00<00:00, 69.41it/s]\n",
            "[8 / 30] Train: Loss = 0.00950, Accuracy = 99.17%: 100%|██████████| 572/572 [00:05<00:00, 103.42it/s]\n",
            "[8 / 30]   Val: Loss = 0.04018, Accuracy = 96.17%: 100%|██████████| 13/13 [00:00<00:00, 70.79it/s]\n",
            "[9 / 30] Train: Loss = 0.00653, Accuracy = 99.46%: 100%|██████████| 572/572 [00:05<00:00, 104.50it/s]\n",
            "[9 / 30]   Val: Loss = 0.04107, Accuracy = 96.28%: 100%|██████████| 13/13 [00:00<00:00, 71.48it/s]\n",
            "[10 / 30] Train: Loss = 0.00429, Accuracy = 99.67%: 100%|██████████| 572/572 [00:05<00:00, 106.60it/s]\n",
            "[10 / 30]   Val: Loss = 0.04410, Accuracy = 96.28%: 100%|██████████| 13/13 [00:00<00:00, 72.55it/s]\n",
            "[11 / 30] Train: Loss = 0.00278, Accuracy = 99.81%: 100%|██████████| 572/572 [00:05<00:00, 107.05it/s]\n",
            "[11 / 30]   Val: Loss = 0.04650, Accuracy = 96.30%: 100%|██████████| 13/13 [00:00<00:00, 71.84it/s]\n",
            "[12 / 30] Train: Loss = 0.00169, Accuracy = 99.91%: 100%|██████████| 572/572 [00:05<00:00, 105.77it/s]\n",
            "[12 / 30]   Val: Loss = 0.04650, Accuracy = 96.26%: 100%|██████████| 13/13 [00:00<00:00, 72.63it/s]\n",
            "[13 / 30] Train: Loss = 0.00147, Accuracy = 99.91%: 100%|██████████| 572/572 [00:05<00:00, 102.90it/s]\n",
            "[13 / 30]   Val: Loss = 0.04914, Accuracy = 96.30%: 100%|██████████| 13/13 [00:00<00:00, 68.36it/s]\n",
            "[14 / 30] Train: Loss = 0.00067, Accuracy = 99.98%: 100%|██████████| 572/572 [00:05<00:00, 103.12it/s]\n",
            "[14 / 30]   Val: Loss = 0.05254, Accuracy = 96.32%: 100%|██████████| 13/13 [00:00<00:00, 67.29it/s]\n",
            "[15 / 30] Train: Loss = 0.00039, Accuracy = 99.99%: 100%|██████████| 572/572 [00:05<00:00, 103.90it/s]\n",
            "[15 / 30]   Val: Loss = 0.05427, Accuracy = 96.34%: 100%|██████████| 13/13 [00:00<00:00, 70.62it/s]\n",
            "[16 / 30] Train: Loss = 0.00027, Accuracy = 99.99%: 100%|██████████| 572/572 [00:05<00:00, 106.33it/s]\n",
            "[16 / 30]   Val: Loss = 0.05475, Accuracy = 96.39%: 100%|██████████| 13/13 [00:00<00:00, 69.59it/s]\n",
            "[17 / 30] Train: Loss = 0.00021, Accuracy = 99.99%: 100%|██████████| 572/572 [00:05<00:00, 106.22it/s]\n",
            "[17 / 30]   Val: Loss = 0.05304, Accuracy = 96.34%: 100%|██████████| 13/13 [00:00<00:00, 70.26it/s]\n",
            "[18 / 30] Train: Loss = 0.00151, Accuracy = 99.85%: 100%|██████████| 572/572 [00:05<00:00, 103.33it/s]\n",
            "[18 / 30]   Val: Loss = 0.05877, Accuracy = 96.15%: 100%|██████████| 13/13 [00:00<00:00, 70.61it/s]\n",
            "[19 / 30] Train: Loss = 0.00093, Accuracy = 99.92%: 100%|██████████| 572/572 [00:05<00:00, 103.47it/s]\n",
            "[19 / 30]   Val: Loss = 0.06360, Accuracy = 96.38%: 100%|██████████| 13/13 [00:00<00:00, 70.49it/s]\n",
            "[20 / 30] Train: Loss = 0.00030, Accuracy = 99.99%: 100%|██████████| 572/572 [00:05<00:00, 102.57it/s]\n",
            "[20 / 30]   Val: Loss = 0.05624, Accuracy = 96.36%: 100%|██████████| 13/13 [00:00<00:00, 69.54it/s]\n",
            "[21 / 30] Train: Loss = 0.00009, Accuracy = 100.00%: 100%|██████████| 572/572 [00:05<00:00, 105.09it/s]\n",
            "[21 / 30]   Val: Loss = 0.06099, Accuracy = 96.39%: 100%|██████████| 13/13 [00:00<00:00, 72.00it/s]\n",
            "[22 / 30] Train: Loss = 0.00007, Accuracy = 100.00%: 100%|██████████| 572/572 [00:05<00:00, 103.93it/s]\n",
            "[22 / 30]   Val: Loss = 0.06031, Accuracy = 96.37%: 100%|██████████| 13/13 [00:00<00:00, 69.35it/s]\n",
            "[23 / 30] Train: Loss = 0.00004, Accuracy = 100.00%: 100%|██████████| 572/572 [00:05<00:00, 102.53it/s]\n",
            "[23 / 30]   Val: Loss = 0.06399, Accuracy = 96.36%: 100%|██████████| 13/13 [00:00<00:00, 69.40it/s]\n",
            "[24 / 30] Train: Loss = 0.00003, Accuracy = 100.00%: 100%|██████████| 572/572 [00:05<00:00, 104.34it/s]\n",
            "[24 / 30]   Val: Loss = 0.06355, Accuracy = 96.39%: 100%|██████████| 13/13 [00:00<00:00, 69.80it/s]\n",
            "[25 / 30] Train: Loss = 0.00003, Accuracy = 100.00%: 100%|██████████| 572/572 [00:05<00:00, 101.91it/s]\n",
            "[25 / 30]   Val: Loss = 0.06508, Accuracy = 96.35%: 100%|██████████| 13/13 [00:00<00:00, 69.54it/s]\n",
            "[26 / 30] Train: Loss = 0.00054, Accuracy = 99.95%: 100%|██████████| 572/572 [00:05<00:00, 104.09it/s]\n",
            "[26 / 30]   Val: Loss = 0.07040, Accuracy = 95.96%: 100%|██████████| 13/13 [00:00<00:00, 71.79it/s]\n",
            "[27 / 30] Train: Loss = 0.00215, Accuracy = 99.78%: 100%|██████████| 572/572 [00:05<00:00, 104.65it/s]\n",
            "[27 / 30]   Val: Loss = 0.06825, Accuracy = 95.98%: 100%|██████████| 13/13 [00:00<00:00, 72.90it/s]\n",
            "[28 / 30] Train: Loss = 0.00025, Accuracy = 99.98%: 100%|██████████| 572/572 [00:05<00:00, 103.87it/s]\n",
            "[28 / 30]   Val: Loss = 0.06486, Accuracy = 96.20%: 100%|██████████| 13/13 [00:00<00:00, 66.60it/s]\n",
            "[29 / 30] Train: Loss = 0.00007, Accuracy = 100.00%: 100%|██████████| 572/572 [00:05<00:00, 102.92it/s]\n",
            "[29 / 30]   Val: Loss = 0.06971, Accuracy = 96.27%: 100%|██████████| 13/13 [00:00<00:00, 72.75it/s]\n",
            "[30 / 30] Train: Loss = 0.00004, Accuracy = 100.00%: 100%|██████████| 572/572 [00:05<00:00, 101.63it/s]\n",
            "[30 / 30]   Val: Loss = 0.06849, Accuracy = 96.28%: 100%|██████████| 13/13 [00:00<00:00, 71.01it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Co8cZXNd5oYs",
        "colab_type": "code",
        "outputId": "851f9502-2bba-4648-cd90-94f23e140c88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "_ = do_epoch(bilstm_tagger, criterion, (X_test, y_test), 64, None, 'Test:')"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test: Loss = 0.10573, Accuracy = 96.32%: 100%|██████████| 224/224 [00:01<00:00, 201.97it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZTXmYGD_ANhm"
      },
      "source": [
        "### Предобученные эмбеддинги\n",
        "\n",
        "Мы знаем, какая клёвая вещь - предобученные эмбеддинги. При текущем размере обучающей выборки еще можно было учить их и с нуля - с меньшей было бы совсем плохо.\n",
        "\n",
        "Поэтому стандартный пайплайн - скачать эмбеддинги, засунуть их в сеточку. Запустим его:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uZpY_Q1xZ18h",
        "outputId": "7553f58e-4c77-4ad4-9383-da07039be80d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "import gensim.downloader as api\n",
        "\n",
        "w2v_model = api.load('glove-wiki-gigaword-100')"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[==================================================] 100.0% 128.1/128.1MB downloaded\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:410: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "KYogOoKlgtcf"
      },
      "source": [
        "Построим подматрицу для слов из нашей тренировочной выборки:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VsCstxiO03oT",
        "outputId": "369ae6e7-d2f4-4fd8-9dcd-b3d1f026fd6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "known_count = 0\n",
        "embeddings = np.zeros((len(word2ind), w2v_model.vectors.shape[1]))\n",
        "for word, ind in word2ind.items():\n",
        "    word = word.lower()\n",
        "    if word in w2v_model.vocab:\n",
        "        embeddings[ind] = w2v_model.get_vector(word)\n",
        "        known_count += 1\n",
        "        \n",
        "print('Know {} out of {} word embeddings'.format(known_count, len(word2ind)))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Know 38736 out of 45441 word embeddings\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HcG7i-R8hbY3"
      },
      "source": [
        "**Задание** Сделайте модель с предобученной матрицей. Используйте `nn.Embedding.from_pretrained`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LxaRBpQd0pat",
        "colab": {}
      },
      "source": [
        "class BiLSTMTaggerWithPretrainedEmbs(nn.Module):\n",
        "    def __init__(self, embeddings, tagset_size, lstm_hidden_dim=64, lstm_layers_count=1):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.embedding = nn.Embedding.from_pretrained(FloatTensor(embeddings))\n",
        "        self.lstm = nn.LSTM(embeddings.shape[1], lstm_hidden_dim, num_layers=lstm_layers_count, bidirectional=True)\n",
        "        self.fc = nn.Linear(2 * lstm_hidden_dim, tagset_size)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        result = self.embedding.forward(inputs)\n",
        "        result, _ = self.lstm.forward(result)\n",
        "        result = self.fc.forward(result)\n",
        "        return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EBtI6BDE-Fc7",
        "outputId": "8e127912-07be-4d7f-d130-e0c5a8bf08d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "pretrained_bilstm_tagger = BiLSTMTaggerWithPretrainedEmbs(\n",
        "    embeddings=embeddings,\n",
        "    tagset_size=len(tag2ind),\n",
        "    lstm_hidden_dim=256,\n",
        "    lstm_layers_count=2,\n",
        ").cuda()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
        "optimizer = optim.Adam(pretrained_bilstm_tagger.parameters())\n",
        "\n",
        "fit(pretrained_bilstm_tagger, criterion, optimizer, train_data=(X_train, y_train), epochs_count=10,\n",
        "    batch_size=128, val_data=(X_val, y_val), val_batch_size=512)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 / 10] Train: Loss = 0.50381, Accuracy = 84.11%: 100%|██████████| 286/286 [00:09<00:00, 30.28it/s]\n",
            "[1 / 10]   Val: Loss = 0.19860, Accuracy = 93.83%: 100%|██████████| 13/13 [00:00<00:00, 20.98it/s]\n",
            "[2 / 10] Train: Loss = 0.14018, Accuracy = 95.66%: 100%|██████████| 286/286 [00:09<00:00, 30.32it/s]\n",
            "[2 / 10]   Val: Loss = 0.13728, Accuracy = 95.64%: 100%|██████████| 13/13 [00:00<00:00, 21.31it/s]\n",
            "[3 / 10] Train: Loss = 0.09637, Accuracy = 96.99%: 100%|██████████| 286/286 [00:09<00:00, 30.30it/s]\n",
            "[3 / 10]   Val: Loss = 0.10984, Accuracy = 96.49%: 100%|██████████| 13/13 [00:00<00:00, 21.79it/s]\n",
            "[4 / 10] Train: Loss = 0.07644, Accuracy = 97.57%: 100%|██████████| 286/286 [00:09<00:00, 30.16it/s]\n",
            "[4 / 10]   Val: Loss = 0.09836, Accuracy = 96.81%: 100%|██████████| 13/13 [00:00<00:00, 20.62it/s]\n",
            "[5 / 10] Train: Loss = 0.06330, Accuracy = 97.99%: 100%|██████████| 286/286 [00:09<00:00, 30.33it/s]\n",
            "[5 / 10]   Val: Loss = 0.09725, Accuracy = 96.84%: 100%|██████████| 13/13 [00:00<00:00, 20.70it/s]\n",
            "[6 / 10] Train: Loss = 0.05365, Accuracy = 98.27%: 100%|██████████| 286/286 [00:09<00:00, 30.55it/s]\n",
            "[6 / 10]   Val: Loss = 0.09666, Accuracy = 96.88%: 100%|██████████| 13/13 [00:00<00:00, 20.27it/s]\n",
            "[7 / 10] Train: Loss = 0.04414, Accuracy = 98.57%: 100%|██████████| 286/286 [00:09<00:00, 30.36it/s]\n",
            "[7 / 10]   Val: Loss = 0.09799, Accuracy = 96.95%: 100%|██████████| 13/13 [00:00<00:00, 20.31it/s]\n",
            "[8 / 10] Train: Loss = 0.03652, Accuracy = 98.83%: 100%|██████████| 286/286 [00:09<00:00, 30.38it/s]\n",
            "[8 / 10]   Val: Loss = 0.09512, Accuracy = 97.08%: 100%|██████████| 13/13 [00:00<00:00, 20.56it/s]\n",
            "[9 / 10] Train: Loss = 0.02888, Accuracy = 99.06%: 100%|██████████| 286/286 [00:09<00:00, 30.38it/s]\n",
            "[9 / 10]   Val: Loss = 0.09842, Accuracy = 97.08%: 100%|██████████| 13/13 [00:00<00:00, 20.31it/s]\n",
            "[10 / 10] Train: Loss = 0.02181, Accuracy = 99.33%: 100%|██████████| 286/286 [00:09<00:00, 30.21it/s]\n",
            "[10 / 10]   Val: Loss = 0.10639, Accuracy = 97.09%: 100%|██████████| 13/13 [00:00<00:00, 21.03it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2Ne_8f24h8kg"
      },
      "source": [
        "**Задание** Оцените качество модели на тестовой выборке. Обратите внимание, вовсе не обязательно ограничиваться векторами из урезанной матрицы - вполне могут найтись слова в тесте, которых не было в трейне и для которых есть эмбеддинги.\n",
        "\n",
        "Добейтесь качества лучше прошлых моделей."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HPUuAPGhEGVR",
        "outputId": "86f40f96-0df3-4fd2-f31d-1c121f71d453",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "_ = do_epoch(pretrained_bilstm_tagger, criterion, (X_test, y_test), 512, None, 'Test:')"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test: Loss = 0.10258, Accuracy = 97.13%: 100%|██████████| 28/28 [00:01<00:00, 21.85it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-5VhK_k_NcS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}