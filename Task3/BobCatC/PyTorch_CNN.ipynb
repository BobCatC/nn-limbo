{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "PyTorch_CNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6i294kFK_I6j",
        "colab_type": "text"
      },
      "source": [
        "# Задание 3.2 - сверточные нейронные сети (CNNs) в PyTorch\n",
        "\n",
        "Это упражнение мы буде выполнять в Google Colab - https://colab.research.google.com/  \n",
        "Google Colab позволяет запускать код в notebook в облаке Google, где можно воспользоваться бесплатным GPU!  \n",
        "\n",
        "Авторы курса благодарят компанию Google и надеятся, что праздник не закончится.\n",
        "\n",
        "Туториал по настройке Google Colab:  \n",
        "https://medium.com/deep-learning-turkey/google-colab-free-gpu-tutorial-e113627b9f5d  \n",
        "(Keras инсталлировать не нужно, наш notebook сам установит PyTorch)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FcXBeP1O7cnY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bc70ad0-c7b2-497c-f5a5-73a68f947ff8"
      },
      "source": [
        "# Intstall PyTorch and download data\n",
        "!pip3 install torch torchvision\n",
        "\n",
        "!wget -c http://ufldl.stanford.edu/housenumbers/train_32x32.mat http://ufldl.stanford.edu/housenumbers/test_32x32.mat"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.4.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.5.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.18.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.12.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (7.0.0)\n",
            "--2020-03-18 19:35:48--  http://ufldl.stanford.edu/housenumbers/train_32x32.mat\n",
            "Resolving ufldl.stanford.edu (ufldl.stanford.edu)... 171.64.68.10\n",
            "Connecting to ufldl.stanford.edu (ufldl.stanford.edu)|171.64.68.10|:80... connected.\n",
            "HTTP request sent, awaiting response... 416 Requested Range Not Satisfiable\n",
            "\n",
            "    The file is already fully retrieved; nothing to do.\n",
            "\n",
            "--2020-03-18 19:35:48--  http://ufldl.stanford.edu/housenumbers/test_32x32.mat\n",
            "Reusing existing connection to ufldl.stanford.edu:80.\n",
            "HTTP request sent, awaiting response... 416 Requested Range Not Satisfiable\n",
            "\n",
            "    The file is already fully retrieved; nothing to do.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-afwWw-Q85vD",
        "colab": {}
      },
      "source": [
        "from collections import namedtuple\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import PIL\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.datasets as dset\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "\n",
        "from torchvision import transforms"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NNU-OD9O9ltP",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda:0\") # Let's make sure GPU is available!"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tNILypG4_I7c",
        "colab_type": "text"
      },
      "source": [
        "# Загружаем данные"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YAvkoRx-9FsP",
        "colab": {}
      },
      "source": [
        "# First, lets load the dataset\n",
        "data_train = dset.SVHN('./', \n",
        "                       transform=transforms.Compose([\n",
        "                           transforms.ToTensor(),\n",
        "                           transforms.Normalize(mean=[0.43,0.44,0.47],\n",
        "                                               std=[0.20,0.20,0.20])                           \n",
        "                       ])\n",
        "                      )\n",
        "data_test = dset.SVHN('./', split='test', transform=transforms.Compose([\n",
        "                           transforms.ToTensor(),\n",
        "                           transforms.Normalize(mean=[0.43,0.44,0.47],\n",
        "                                               std=[0.20,0.20,0.20])                           \n",
        "                       ]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gs5m0gKe_I7x",
        "colab_type": "text"
      },
      "source": [
        "Разделяем данные на training и validation.\n",
        "\n",
        "На всякий случай для подробностей - https://pytorch.org/tutorials/beginner/data_loading_tutorial.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YRnr8CPg7Hli",
        "colab": {}
      },
      "source": [
        "batch_size = 64\n",
        "\n",
        "data_size = data_train.data.shape[0]\n",
        "validation_split = .2\n",
        "split = int(np.floor(validation_split * data_size))\n",
        "indices = list(range(data_size))\n",
        "np.random.shuffle(indices)\n",
        "\n",
        "train_indices, val_indices = indices[split:], indices[:split]\n",
        "\n",
        "train_sampler = SubsetRandomSampler(train_indices)\n",
        "val_sampler = SubsetRandomSampler(val_indices)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(data_train, batch_size=batch_size, \n",
        "                                           sampler=train_sampler)\n",
        "val_loader = torch.utils.data.DataLoader(data_train, batch_size=batch_size,\n",
        "                                         sampler=val_sampler)\n",
        "test_loader = torch.utils.data.DataLoader(data_test, batch_size=batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LyYvt-T67PBG",
        "colab": {}
      },
      "source": [
        "# We'll use a special helper module to shape it into a flat tensor\n",
        "class Flattener(nn.Module):\n",
        "    def forward(self, x):\n",
        "        batch_size, *_ = x.shape\n",
        "        return x.view(batch_size, -1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7NQfaeZp_I8D",
        "colab_type": "text"
      },
      "source": [
        "Создадим простейшую сеть с новыми слоями:  \n",
        "Convolutional - `nn.Conv2d`  \n",
        "MaxPool - `nn.MaxPool2d`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "w9SFVGZP7SQd",
        "colab": {}
      },
      "source": [
        "nn_model = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, 3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(4),\n",
        "            nn.Conv2d(64, 64, 3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(4),    \n",
        "            Flattener(),\n",
        "            nn.Linear(64*2*2, 10),\n",
        "          )\n",
        "\n",
        "nn_model.type(torch.cuda.FloatTensor)\n",
        "nn_model.to(device)\n",
        "\n",
        "loss = nn.CrossEntropyLoss().type(torch.cuda.FloatTensor)\n",
        "optimizer = optim.SGD(nn_model.parameters(), lr=1e-1, weight_decay=1e-4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_zRxtgog_I8K",
        "colab_type": "text"
      },
      "source": [
        "Восстановите функцию `compute_accuracy` из прошлого задания.  \n",
        "Единственное отличие в новом - она должна передать данные на GPU прежде чем прогонять через модель. Сделайте это так же, как это делает функция `train_model`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2ek3KVQK7hJ6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc147a65-6c99-42a2-9768-41ceef6099a0"
      },
      "source": [
        "def train_model(model, train_loader, val_loader, loss, optimizer, num_epochs, scheduler=None):    \n",
        "    loss_history = []\n",
        "    train_history = []\n",
        "    val_history = []\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train() # Enter train mode\n",
        "        \n",
        "        loss_accum = 0\n",
        "        correct_samples = 0\n",
        "        total_samples = 0\n",
        "        for i_step, (x, y) in enumerate(train_loader):\n",
        "          \n",
        "            x_gpu = x.to(device)\n",
        "            y_gpu = y.to(device)\n",
        "            prediction = model(x_gpu)    \n",
        "            loss_value = loss(prediction, y_gpu)\n",
        "            optimizer.zero_grad()\n",
        "            loss_value.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            _, indices = torch.max(prediction, 1)\n",
        "            correct_samples += torch.sum(indices == y_gpu)\n",
        "            total_samples += y.shape[0]\n",
        "            \n",
        "            loss_accum += loss_value\n",
        "\n",
        "        ave_loss = loss_accum / i_step\n",
        "        train_accuracy = float(correct_samples) / total_samples\n",
        "        val_accuracy = compute_accuracy(model, val_loader)\n",
        "        \n",
        "        loss_history.append(float(ave_loss))\n",
        "        train_history.append(train_accuracy)\n",
        "        val_history.append(val_accuracy)\n",
        "        \n",
        "        output = [\n",
        "            \"Average loss: %f\" % ave_loss,\n",
        "            \"Train accuracy: %f\" % train_accuracy,\n",
        "            \"Val accuracy: %f\" % val_accuracy\n",
        "        ]\n",
        "        \n",
        "        if scheduler:\n",
        "            output.append(\"Learning rate: {}\".format(scheduler.get_lr()))\n",
        "            \n",
        "        print(\", \".join(output))\n",
        "        \n",
        "        if scheduler:\n",
        "            scheduler.step()\n",
        "        \n",
        "    return loss_history, train_history, val_history\n",
        "        \n",
        "def compute_accuracy(model, loader):\n",
        "    \"\"\"\n",
        "    Computes accuracy on the dataset wrapped in a loader\n",
        "    \n",
        "    Returns: accuracy as a float value between 0 and 1\n",
        "    \"\"\"\n",
        "    model.eval() # Evaluation mode\n",
        "\n",
        "    total_hits_count = 0\n",
        "    total_inputs_count = 0\n",
        "    \n",
        "    for x, y in loader:\n",
        "      x_gpu = x.to(device)\n",
        "      y_gpu = y.to(device)\n",
        "\n",
        "      prediction = model(x_gpu)\n",
        "\n",
        "      prediction = model(x_gpu)\n",
        "      probs = torch.argmax(prediction.data, axis=1)\n",
        "      \n",
        "      total_hits_count += (probs == y_gpu).sum().item()\n",
        "      total_inputs_count += x_gpu.shape[0]\n",
        "    \n",
        "    return total_hits_count / total_inputs_count if total_inputs_count > 0 else 0.0\n",
        "\n",
        "loss_history, train_history, val_history = train_model(nn_model, train_loader, val_loader, loss, optimizer, 5)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average loss: 1.419086, Train accuracy: 0.524759, Val accuracy: 0.732988\n",
            "Average loss: 0.702837, Train accuracy: 0.785807, Val accuracy: 0.802061\n",
            "Average loss: 0.596769, Train accuracy: 0.821093, Val accuracy: 0.808136\n",
            "Average loss: 0.549695, Train accuracy: 0.836058, Val accuracy: 0.841649\n",
            "Average loss: 0.516416, Train accuracy: 0.846756, Val accuracy: 0.827930\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6a-3a1ZFGEw_"
      },
      "source": [
        "# Аугментация данных (Data augmentation)\n",
        "\n",
        "В работе с изображениями одним из особенно важных методов является аугментация данных - то есть, генерация дополнительных данных для тренировки на основе изначальных.   \n",
        "Таким образом, мы получаем возможность \"увеличить\" набор данных для тренировки, что ведет к лучшей работе сети.\n",
        "Важно, чтобы аугментированные данные были похожи на те, которые могут встретиться в реальной жизни, иначе польза от аугментаций уменьшается и может ухудшить работу сети.\n",
        "\n",
        "С PyTorch идут несколько таких алгоритмов, называемых `transforms`. Более подробно про них можно прочитать тут -\n",
        "https://pytorch.org/tutorials/beginner/data_loading_tutorial.html#transforms\n",
        "\n",
        "Ниже мы используем следующие алгоритмы генерации:\n",
        "- ColorJitter - случайное изменение цвета\n",
        "- RandomHorizontalFlip - горизонтальное отражение с вероятностью 50%\n",
        "- RandomVerticalFlip - вертикальное отражение с вероятностью 50%\n",
        "- RandomRotation - случайный поворот"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jCWMUWmr7t5g",
        "colab": {}
      },
      "source": [
        "tfs = transforms.Compose([\n",
        "    transforms.ColorJitter(hue=.50, saturation=.50),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomVerticalFlip(),\n",
        "    transforms.RandomRotation(50, resample=PIL.Image.BILINEAR),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.43,0.44,0.47],\n",
        "                       std=[0.20,0.20,0.20])                           \n",
        "])\n",
        "\n",
        "# Create augmented train dataset\n",
        "data_aug_train = dset.SVHN('./', \n",
        "                       transform=tfs\n",
        "                      )\n",
        "\n",
        "train_aug_loader = torch.utils.data.DataLoader(data_aug_train, batch_size=batch_size, \n",
        "                                           sampler=train_sampler)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I0vnxJsM_I8Y",
        "colab_type": "text"
      },
      "source": [
        "Визуализируем результаты агментации (вообще, смотреть на сгенерированные данные всегда очень полезно)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YlJJEro1KZ45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "outputId": "49d153e1-a2b8-4435-90ad-308b3ab9425a"
      },
      "source": [
        "# TODO: Visualize some augmented images!\n",
        "# hint: you can create new datasets and loaders to accomplish this\n",
        "\n",
        "# Based on the visualizations, should we keep all the augmentations?\n",
        "\n",
        "tfs = transforms.Compose([\n",
        "    transforms.ColorJitter(hue=0.2, saturation=.2),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomVerticalFlip(),\n",
        "    transforms.RandomRotation(10, resample=PIL.Image.BILINEAR),\n",
        "])\n",
        "\n",
        "data_aug_vis = dset.SVHN('./', \n",
        "                       transform=tfs\n",
        "                      )\n",
        "\n",
        "plt.figure(figsize=(30, 3))\n",
        "\n",
        "for i, (x, y) in enumerate(data_aug_vis):\n",
        "    if i == 10:\n",
        "        break\n",
        "    plt.subplot(1, 10, i+1)\n",
        "    plt.grid(False)\n",
        "    plt.imshow(x)\n",
        "    plt.axis('off')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABpgAAACcCAYAAABr5qh0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 2160x216 with 10 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "o2LrmsYHoguB"
      },
      "source": [
        "Все ли агментации одинаково полезны на этом наборе данных? Могут ли быть среди них те, которые собьют модель с толку?\n",
        "\n",
        "Выберите из них только корректные"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "evro9ksXGs9u",
        "colab": {}
      },
      "source": [
        "tfs = transforms.Compose([\n",
        "    transforms.ColorJitter(hue=0.2, saturation=.2),\n",
        "    # transforms.RandomHorizontalFlip(),\n",
        "    # transforms.RandomVerticalFlip(),\n",
        "    transforms.RandomRotation(10, resample=PIL.Image.BILINEAR),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.43,0.44,0.47],\n",
        "                       std=[0.20,0.20,0.20])                           \n",
        "])\n",
        "\n",
        "data_aug_train = dset.SVHN('./', transform=tfs)\n",
        "\n",
        "train_aug_loader = torch.utils.data.DataLoader(data_aug_train, batch_size=batch_size, sampler=train_sampler)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PeO6Zw0DHqPR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "08913036-0c03-4ea2-c73e-8444eb4cf969"
      },
      "source": [
        "# Finally, let's train with augmentations!\n",
        "\n",
        "# Note we shouldn't use augmentations on validation\n",
        "\n",
        "loss_history, train_history, val_history = train_model(nn_model, train_aug_loader, val_loader, loss, optimizer, 5)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average loss: 0.590785, Train accuracy: 0.818227, Val accuracy: 0.831752\n",
            "Average loss: 0.555333, Train accuracy: 0.831673, Val accuracy: 0.849567\n",
            "Average loss: 0.531672, Train accuracy: 0.839163, Val accuracy: 0.830182\n",
            "Average loss: 0.518761, Train accuracy: 0.842030, Val accuracy: 0.839533\n",
            "Average loss: 0.505930, Train accuracy: 0.847217, Val accuracy: 0.850590\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "r0bcioK6JBDK"
      },
      "source": [
        "# LeNet\n",
        "Попробуем имплементировать классическую архитектуру сверточной нейронной сети, предложенную Яном ЛеКуном в 1998 году. В свое время она достигла впечатляющих результатов на MNIST, посмотрим как она справится с SVHN?\n",
        "Она описана в статье [\"Gradient Based Learning Applied to Document Recognition\"](http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf), попробуйте прочитать ключевые части и имплементировать предложенную архитетуру на PyTorch.\n",
        "\n",
        "Реализовывать слои и функцию ошибки LeNet, которых нет в PyTorch, **не нужно** - просто возьмите их размеры и переведите в уже известные нам Convolutional, Pooling и Fully Connected layers.\n",
        "\n",
        "Если в статье не очень понятно, можно просто погуглить LeNet и разобраться в деталях :)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ieEzZUglJAUB",
        "colab": {}
      },
      "source": [
        "# TODO: Implement LeNet-like architecture for SVHN task\n",
        "lenet_model = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=3, out_channels=6, kernel_size=5, stride=1, padding=2),\n",
        "            nn.Tanh(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0),\n",
        "            nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1, padding=0),\n",
        "            nn.Tanh(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0),\n",
        "            Flattener(),\n",
        "            nn.Linear(16 * 6 * 6, 10),\n",
        "          )\n",
        "\n",
        "lenet_model.type(torch.cuda.FloatTensor)\n",
        "lenet_model.to(device)\n",
        "\n",
        "loss = nn.CrossEntropyLoss().type(torch.cuda.FloatTensor)\n",
        "optimizer = optim.SGD(lenet_model.parameters(), lr=1e-1, weight_decay=1e-4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WMmaPfdeKk9H",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "139ad8cf-c58b-40f3-dea4-8a3a34b296bf"
      },
      "source": [
        "# Let's train it!\n",
        "loss_history, train_history, val_history = train_model(lenet_model, train_aug_loader, val_loader, loss, optimizer, 10)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average loss: 0.957739, Train accuracy: 0.696465, Val accuracy: 0.840762\n",
            "Average loss: 0.551307, Train accuracy: 0.832338, Val accuracy: 0.849430\n",
            "Average loss: 0.508529, Train accuracy: 0.846040, Val accuracy: 0.845881\n",
            "Average loss: 0.488551, Train accuracy: 0.852899, Val accuracy: 0.858098\n",
            "Average loss: 0.474225, Train accuracy: 0.857660, Val accuracy: 0.855163\n",
            "Average loss: 0.465750, Train accuracy: 0.859246, Val accuracy: 0.861784\n",
            "Average loss: 0.458982, Train accuracy: 0.862164, Val accuracy: 0.868883\n",
            "Average loss: 0.457746, Train accuracy: 0.862113, Val accuracy: 0.867995\n",
            "Average loss: 0.451237, Train accuracy: 0.863615, Val accuracy: 0.873046\n",
            "Average loss: 0.451504, Train accuracy: 0.864775, Val accuracy: 0.872500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "u_O9qiYySvuj"
      },
      "source": [
        "# Подбор гиперпараметров"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "i6mhfdQ9K-N3",
        "colab": {}
      },
      "source": [
        "# The key hyperparameters we're going to tune are learning speed, annealing rate and regularization\n",
        "# We also encourage you to try different optimizers as well\n",
        "import itertools\n",
        "\n",
        "RunResult = namedtuple(\"RunResult\", ['model', 'train_history', 'val_history', 'final_val_accuracy'])\n",
        "\n",
        "\n",
        "class GridSearchIterator:\n",
        "  def __init__(self, hparams):\n",
        "    self.Hyperparams = namedtuple(\"Hyperparams\", list(hparams.keys()))\n",
        "    self.__combinations = list(itertools.product(*(hparams.values())))\n",
        "    self.__index = 0\n",
        "    self.__keys = list(hparams.keys())\n",
        "\n",
        "  def __next__(self):\n",
        "    if self.__index >= len(self.__combinations):\n",
        "      raise StopIteration\n",
        "    \n",
        "    hparams = self.__combinations[self.__index]\n",
        "    hparams = { key: value for (key, value) in zip(self.__keys, hparams) }\n",
        "    self.__index += 1\n",
        "    return self.Hyperparams(**hparams)\n",
        "\n",
        "\n",
        "class GridSearch:\n",
        "  def __init__(self, **kwargs):\n",
        "    self.parameters = kwargs\n",
        "  \n",
        "  def __iter__(self):\n",
        "    return GridSearchIterator(self.parameters)\n",
        "\n",
        "\n",
        "def grid_search_train(train_lambda, grid_search, metric):\n",
        "  results = []\n",
        "  for hparams in grid_search:\n",
        "    print(\"Executing with hparams: {}\".format(hparams))\n",
        "    run_result = train_lambda(hparams)\n",
        "    results.append((hparams, run_result))\n",
        "  \n",
        "  best_result = max(results, key=lambda x: getattr(x[1], metric))\n",
        "  print(\"Best hyper parameters: {}\".format(best_result[0]))\n",
        "  print(\"Best run result: {}\".format(best_result[1]))\n",
        "  return best_result[0], best_result[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Y6xExdw8JB1l",
        "outputId": "3c7542dd-d518-479e-f121-2c34aa91e845",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "def train_lenet(hparams):\n",
        "  global data_aug_train, train_sampler, val_loader\n",
        "\n",
        "  learning_rate = hparams.learning_rate\n",
        "  step_size = hparams.scheduler_step_size\n",
        "  gamma = hparams.scheduler_gamma\n",
        "  reg = hparams.reg\n",
        "  batch_size = hparams.batch_size\n",
        "  epoch_num = hparams.epoch_num\n",
        "\n",
        "  train_aug_loader = torch.utils.data.DataLoader(data_aug_train, batch_size=batch_size, sampler=train_sampler)\n",
        "\n",
        "  lenet_model = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=3, out_channels=6, kernel_size=5, stride=1, padding=2),\n",
        "            nn.Tanh(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0),\n",
        "            nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1, padding=0),\n",
        "            nn.Tanh(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0),\n",
        "            Flattener(),\n",
        "            nn.Linear(16 * 6 * 6, 10),\n",
        "          )\n",
        "  \n",
        "  lenet_model.type(torch.cuda.FloatTensor)\n",
        "  lenet_model.to(device)\n",
        "\n",
        "  loss = nn.CrossEntropyLoss().type(torch.cuda.FloatTensor)\n",
        "  optimizer = optim.SGD(lenet_model.parameters(), lr=learning_rate, weight_decay=reg)\n",
        "  scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
        "\n",
        "  loss_history, train_history, val_history = train_model(lenet_model, train_aug_loader, val_loader, loss, optimizer, epoch_num, scheduler)\n",
        "\n",
        "  return RunResult(model=lenet_model, train_history=train_history, val_history=val_history, final_val_accuracy=val_history[-1])\n",
        "  \n",
        "\n",
        "grid_search = GridSearch(\n",
        "    learning_rate=[1e-1, 75e-3, 5e-2],\n",
        "    scheduler_gamma=[0.5],\n",
        "    scheduler_step_size=[2, 4],\n",
        "    reg=[1e-4],\n",
        "    batch_size=[64],\n",
        "    epoch_num=[10]\n",
        ")\n",
        "\n",
        "best_hyperparams, best_run_result = grid_search_train(train_lenet, grid_search, 'final_val_accuracy')\n",
        "\n",
        "best_val_accuracy = best_run_result.final_val_accuracy\n",
        "best_run = best_run_result\n",
        "\n",
        "print(\"Best validation accuracy: %4.2f, best hyperparams: %s\" % (best_val_accuracy, best_hyperparams))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Executing with hparams: Hyperparams(learning_rate=0.1, scheduler_gamma=0.5, scheduler_step_size=2, reg=0.0001, batch_size=64, epoch_num=10)\n",
            "Average loss: 0.966191, Train accuracy: 0.692796, Val accuracy: 0.840079, Learning rate: [0.1]\n",
            "Average loss: 0.546137, Train accuracy: 0.834642, Val accuracy: 0.854890, Learning rate: [0.1]\n",
            "Average loss: 0.482264, Train accuracy: 0.856312, Val accuracy: 0.865265, Learning rate: [0.025]\n",
            "Average loss: 0.465357, Train accuracy: 0.862608, Val accuracy: 0.871340, Learning rate: [0.05]\n",
            "Average loss: 0.443756, Train accuracy: 0.868938, Val accuracy: 0.880691, Learning rate: [0.0125]\n",
            "Average loss: 0.437061, Train accuracy: 0.870201, Val accuracy: 0.878711, Learning rate: [0.025]\n",
            "Average loss: 0.428151, Train accuracy: 0.872129, Val accuracy: 0.881237, Learning rate: [0.00625]\n",
            "Average loss: 0.424372, Train accuracy: 0.874040, Val accuracy: 0.881237, Learning rate: [0.0125]\n",
            "Average loss: 0.421856, Train accuracy: 0.876020, Val accuracy: 0.884240, Learning rate: [0.003125]\n",
            "Average loss: 0.418528, Train accuracy: 0.876531, Val accuracy: 0.883762, Learning rate: [0.00625]\n",
            "Executing with hparams: Hyperparams(learning_rate=0.1, scheduler_gamma=0.5, scheduler_step_size=4, reg=0.0001, batch_size=64, epoch_num=10)\n",
            "Average loss: 1.029529, Train accuracy: 0.670051, Val accuracy: 0.837144, Learning rate: [0.1]\n",
            "Average loss: 0.551171, Train accuracy: 0.831604, Val accuracy: 0.859259, Learning rate: [0.1]\n",
            "Average loss: 0.514200, Train accuracy: 0.844436, Val accuracy: 0.866425, Learning rate: [0.1]\n",
            "Average loss: 0.497497, Train accuracy: 0.848906, Val accuracy: 0.864583, Learning rate: [0.1]\n",
            "Average loss: 0.453537, Train accuracy: 0.864092, Val accuracy: 0.875162, Learning rate: [0.025]\n",
            "Average loss: 0.446642, Train accuracy: 0.865372, Val accuracy: 0.878029, Learning rate: [0.05]\n",
            "Average loss: 0.439259, Train accuracy: 0.868734, Val accuracy: 0.873934, Learning rate: [0.05]\n",
            "Average loss: 0.438108, Train accuracy: 0.868034, Val accuracy: 0.876391, Learning rate: [0.05]\n",
            "Average loss: 0.416337, Train accuracy: 0.876463, Val accuracy: 0.882943, Learning rate: [0.0125]\n",
            "Average loss: 0.414514, Train accuracy: 0.876327, Val accuracy: 0.884786, Learning rate: [0.025]\n",
            "Executing with hparams: Hyperparams(learning_rate=0.075, scheduler_gamma=0.5, scheduler_step_size=2, reg=0.0001, batch_size=64, epoch_num=10)\n",
            "Average loss: 1.092477, Train accuracy: 0.646947, Val accuracy: 0.824108, Learning rate: [0.075]\n",
            "Average loss: 0.580602, Train accuracy: 0.824677, Val accuracy: 0.849021, Learning rate: [0.075]\n",
            "Average loss: 0.504629, Train accuracy: 0.849742, Val accuracy: 0.863081, Learning rate: [0.01875]\n",
            "Average loss: 0.487075, Train accuracy: 0.854520, Val accuracy: 0.870248, Learning rate: [0.0375]\n",
            "Average loss: 0.466980, Train accuracy: 0.861516, Val accuracy: 0.870794, Learning rate: [0.009375]\n",
            "Average loss: 0.459068, Train accuracy: 0.863461, Val accuracy: 0.873114, Learning rate: [0.01875]\n",
            "Average loss: 0.450128, Train accuracy: 0.866857, Val accuracy: 0.875299, Learning rate: [0.0046875]\n",
            "Average loss: 0.447108, Train accuracy: 0.867403, Val accuracy: 0.873865, Learning rate: [0.009375]\n",
            "Average loss: 0.440582, Train accuracy: 0.869996, Val accuracy: 0.876459, Learning rate: [0.00234375]\n",
            "Average loss: 0.441152, Train accuracy: 0.868597, Val accuracy: 0.875913, Learning rate: [0.0046875]\n",
            "Executing with hparams: Hyperparams(learning_rate=0.075, scheduler_gamma=0.5, scheduler_step_size=4, reg=0.0001, batch_size=64, epoch_num=10)\n",
            "Average loss: 1.077612, Train accuracy: 0.654643, Val accuracy: 0.823493, Learning rate: [0.075]\n",
            "Average loss: 0.588081, Train accuracy: 0.820923, Val accuracy: 0.834346, Learning rate: [0.075]\n",
            "Average loss: 0.533553, Train accuracy: 0.838549, Val accuracy: 0.855300, Learning rate: [0.075]\n",
            "Average loss: 0.504706, Train accuracy: 0.848872, Val accuracy: 0.862398, Learning rate: [0.075]\n",
            "Average loss: 0.463917, Train accuracy: 0.862198, Val accuracy: 0.873524, Learning rate: [0.01875]\n",
            "Average loss: 0.453410, Train accuracy: 0.864894, Val accuracy: 0.875708, Learning rate: [0.0375]\n",
            "Average loss: 0.447989, Train accuracy: 0.865765, Val accuracy: 0.874138, Learning rate: [0.0375]\n",
            "Average loss: 0.440608, Train accuracy: 0.868495, Val accuracy: 0.875776, Learning rate: [0.0375]\n",
            "Average loss: 0.425479, Train accuracy: 0.873648, Val accuracy: 0.878165, Learning rate: [0.009375]\n",
            "Average loss: 0.421105, Train accuracy: 0.874535, Val accuracy: 0.879394, Learning rate: [0.01875]\n",
            "Executing with hparams: Hyperparams(learning_rate=0.05, scheduler_gamma=0.5, scheduler_step_size=2, reg=0.0001, batch_size=64, epoch_num=10)\n",
            "Average loss: 1.248241, Train accuracy: 0.608521, Val accuracy: 0.822196, Learning rate: [0.05]\n",
            "Average loss: 0.592528, Train accuracy: 0.824301, Val accuracy: 0.845267, Learning rate: [0.05]\n",
            "Average loss: 0.519143, Train accuracy: 0.845801, Val accuracy: 0.861784, Learning rate: [0.0125]\n",
            "Average loss: 0.498015, Train accuracy: 0.851466, Val accuracy: 0.863081, Learning rate: [0.025]\n",
            "Average loss: 0.479609, Train accuracy: 0.858206, Val accuracy: 0.870657, Learning rate: [0.00625]\n",
            "Average loss: 0.474285, Train accuracy: 0.859946, Val accuracy: 0.871886, Learning rate: [0.0125]\n",
            "Average loss: 0.464035, Train accuracy: 0.862028, Val accuracy: 0.873456, Learning rate: [0.003125]\n",
            "Average loss: 0.462356, Train accuracy: 0.864434, Val accuracy: 0.874070, Learning rate: [0.00625]\n",
            "Average loss: 0.458269, Train accuracy: 0.865150, Val accuracy: 0.875299, Learning rate: [0.0015625]\n",
            "Average loss: 0.454297, Train accuracy: 0.866447, Val accuracy: 0.874616, Learning rate: [0.003125]\n",
            "Executing with hparams: Hyperparams(learning_rate=0.05, scheduler_gamma=0.5, scheduler_step_size=4, reg=0.0001, batch_size=64, epoch_num=10)\n",
            "Average loss: 1.250406, Train accuracy: 0.600450, Val accuracy: 0.824176, Learning rate: [0.05]\n",
            "Average loss: 0.585939, Train accuracy: 0.824967, Val accuracy: 0.848475, Learning rate: [0.05]\n",
            "Average loss: 0.523200, Train accuracy: 0.843497, Val accuracy: 0.860146, Learning rate: [0.05]\n",
            "Average loss: 0.494973, Train accuracy: 0.852916, Val accuracy: 0.867040, Learning rate: [0.05]\n",
            "Average loss: 0.465021, Train accuracy: 0.861431, Val accuracy: 0.871340, Learning rate: [0.0125]\n",
            "Average loss: 0.458968, Train accuracy: 0.863393, Val accuracy: 0.874343, Learning rate: [0.025]\n",
            "Average loss: 0.450964, Train accuracy: 0.865492, Val accuracy: 0.873114, Learning rate: [0.025]\n",
            "Average loss: 0.444787, Train accuracy: 0.867061, Val accuracy: 0.875708, Learning rate: [0.025]\n",
            "Average loss: 0.433081, Train accuracy: 0.872010, Val accuracy: 0.877824, Learning rate: [0.00625]\n",
            "Average loss: 0.430949, Train accuracy: 0.872812, Val accuracy: 0.879189, Learning rate: [0.0125]\n",
            "Best hyper parameters: Hyperparams(learning_rate=0.1, scheduler_gamma=0.5, scheduler_step_size=4, reg=0.0001, batch_size=64, epoch_num=10)\n",
            "Best run result: RunResult(model=Sequential(\n",
            "  (0): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "  (1): Tanh()\n",
            "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (3): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (4): Tanh()\n",
            "  (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (6): Flattener()\n",
            "  (7): Linear(in_features=576, out_features=10, bias=True)\n",
            "), train_history=[0.6700508480360373, 0.8316042726000751, 0.8444357233047811, 0.8489062553322185, 0.8640924137460329, 0.8653721461966352, 0.8687335767668839, 0.868033989693888, 0.876463160768522, 0.8763266559737911], val_history=[0.8371442222373899, 0.8592587536686915, 0.8664254999658726, 0.8645826223465976, 0.8751621049757695, 0.878028803494642, 0.8739335198962528, 0.8763906900552864, 0.882943143812709, 0.8847860214319841], final_val_accuracy=0.8847860214319841)\n",
            "Best validation accuracy: 0.88, best hyperparams: Hyperparams(learning_rate=0.1, scheduler_gamma=0.5, scheduler_step_size=4, reg=0.0001, batch_size=64, epoch_num=10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LOmsR0uVgtgf"
      },
      "source": [
        "# Свободное упражнение - догоним и перегоним LeNet!\n",
        "\n",
        "Попробуйте найти архитектуру и настройки тренировки, чтобы выступить лучше наших бейзлайнов.\n",
        "\n",
        "Что можно и нужно попробовать:\n",
        "- BatchNormalization (для convolution layers он в PyTorch называется [batchnorm2d](https://pytorch.org/docs/stable/nn.html#batchnorm2d))\n",
        "- Изменить количество слоев и их толщину\n",
        "- Изменять количество эпох тренировки\n",
        "- Попробовать и другие агментации"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_TDCFdIsQkmn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649
        },
        "outputId": "a0225782-0914-4a63-e389-f231b38128fa"
      },
      "source": [
        "def train_best_model(hparams):\n",
        "  global data_aug_train, train_sampler, val_loader\n",
        "\n",
        "  learning_rate = hparams.learning_rate\n",
        "  step_size = hparams.scheduler_step_size\n",
        "  gamma = hparams.scheduler_gamma\n",
        "  reg = hparams.reg\n",
        "  batch_size = hparams.batch_size\n",
        "  epoch_num = hparams.epoch_num\n",
        "\n",
        "  train_aug_loader = torch.utils.data.DataLoader(data_aug_train, batch_size=batch_size, sampler=train_sampler)\n",
        "\n",
        "  lenet_model = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=3, out_channels=16, kernel_size=5, padding=2),\n",
        "            nn.BatchNorm2d(num_features=16, eps=1e-5, momentum=1e-1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "\n",
        "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=5, padding=0),\n",
        "            nn.BatchNorm2d(num_features=32),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "            \n",
        "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=0),\n",
        "            nn.BatchNorm2d(num_features=64),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            Flattener(),\n",
        "\n",
        "            nn.Linear(64 * 4 * 4, 128),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.ReLU(inplace = True),\n",
        "\n",
        "            nn.Linear(128, 10)\n",
        "          )\n",
        "  \n",
        "  lenet_model.type(torch.cuda.FloatTensor)\n",
        "  lenet_model.to(device)\n",
        "\n",
        "  loss = nn.CrossEntropyLoss().type(torch.cuda.FloatTensor)\n",
        "  optimizer = optim.SGD(lenet_model.parameters(), lr=learning_rate, weight_decay=reg)\n",
        "  scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
        "\n",
        "  loss_history, train_history, val_history = train_model(lenet_model, train_aug_loader, val_loader, loss, optimizer, epoch_num, scheduler)\n",
        "\n",
        "  return RunResult(model=lenet_model, train_history=train_history, val_history=val_history, final_val_accuracy=val_history[-1])\n",
        "  \n",
        "\n",
        "grid_search = GridSearch(\n",
        "    learning_rate=[2e-1, 1e-1, 5e-2],\n",
        "    scheduler_gamma=[0.5],\n",
        "    scheduler_step_size=[5, 10],\n",
        "    reg=[1e-4],\n",
        "    batch_size=[64],\n",
        "    epoch_num=[15]\n",
        ")\n",
        "\n",
        "best_hyperparams, best_run_result = grid_search_train(train_best_model, grid_search, 'final_val_accuracy')\n",
        "\n",
        "best_val_accuracy = best_run_result.final_val_accuracy\n",
        "best_run = best_run_result\n",
        "\n",
        "print(\"Best validation accuracy: %4.2f, best hyperparams: %s\" % (best_val_accuracy, best_hyperparams))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Executing with hparams: Hyperparams(learning_rate=0.1, scheduler_gamma=0.5, scheduler_step_size=10, reg=0.0001, batch_size=64, epoch_num=15)\n",
            "Average loss: 0.629271, Train accuracy: 0.803450, Val accuracy: 0.889223, Learning rate: [0.1]\n",
            "Average loss: 0.387454, Train accuracy: 0.881360, Val accuracy: 0.897618, Learning rate: [0.1]\n",
            "Average loss: 0.327814, Train accuracy: 0.900915, Val accuracy: 0.911474, Learning rate: [0.1]\n",
            "Average loss: 0.292108, Train accuracy: 0.911920, Val accuracy: 0.913385, Learning rate: [0.1]\n",
            "Average loss: 0.268787, Train accuracy: 0.917892, Val accuracy: 0.918777, Learning rate: [0.1]\n",
            "Average loss: 0.246840, Train accuracy: 0.926151, Val accuracy: 0.926558, Learning rate: [0.1]\n",
            "Average loss: 0.231343, Train accuracy: 0.929478, Val accuracy: 0.923486, Learning rate: [0.1]\n",
            "Average loss: 0.215221, Train accuracy: 0.934563, Val accuracy: 0.924920, Learning rate: [0.1]\n",
            "Average loss: 0.201692, Train accuracy: 0.939392, Val accuracy: 0.926490, Learning rate: [0.1]\n",
            "Average loss: 0.188073, Train accuracy: 0.941781, Val accuracy: 0.923282, Learning rate: [0.1]\n",
            "Average loss: 0.151777, Train accuracy: 0.955056, Val accuracy: 0.932155, Learning rate: [0.025]\n",
            "Average loss: 0.140857, Train accuracy: 0.958076, Val accuracy: 0.931882, Learning rate: [0.05]\n",
            "Average loss: 0.131747, Train accuracy: 0.961096, Val accuracy: 0.931677, Learning rate: [0.05]\n",
            "Average loss: 0.126705, Train accuracy: 0.962854, Val accuracy: 0.931063, Learning rate: [0.05]\n",
            "Average loss: 0.121183, Train accuracy: 0.963843, Val accuracy: 0.929288, Learning rate: [0.05]\n",
            "Best hyper parameters: Hyperparams(learning_rate=0.1, scheduler_gamma=0.5, scheduler_step_size=10, reg=0.0001, batch_size=64, epoch_num=15)\n",
            "Best run result: RunResult(model=Sequential(\n",
            "  (0): Conv2d(3, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "  (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): ReLU(inplace=True)\n",
            "  (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (4): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (6): ReLU(inplace=True)\n",
            "  (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (8): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (10): ReLU(inplace=True)\n",
            "  (11): Flattener()\n",
            "  (12): Linear(in_features=1024, out_features=128, bias=True)\n",
            "  (13): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (14): ReLU(inplace=True)\n",
            "  (15): Linear(in_features=128, out_features=10, bias=True)\n",
            "), train_history=[0.8034501586868239, 0.8813602702794936, 0.9009145821246971, 0.9119202811998771, 0.9178923659693546, 0.926150906050575, 0.9294782104221411, 0.9345630140258676, 0.9393918711394738, 0.9417807050472647, 0.9550557963348463, 0.9580759649182677, 0.9610961335016892, 0.9628536327338498, 0.9638432924956489], val_history=[0.8892225786635725, 0.8976179100402703, 0.9114736195481538, 0.9133847518940686, 0.9187768752986144, 0.9265579141355539, 0.923486451436762, 0.9249198006961982, 0.926489659408914, 0.9232816872568426, 0.9321548017200191, 0.9318817828134598, 0.9316770186335404, 0.931062726093782, 0.9292881032011466], final_val_accuracy=0.9292881032011466)\n",
            "Best validation accuracy: 0.93, best hyperparams: Hyperparams(learning_rate=0.1, scheduler_gamma=0.5, scheduler_step_size=10, reg=0.0001, batch_size=64, epoch_num=15)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ubeKgBcnhx7N"
      },
      "source": [
        "# Финальный аккорд - проверим лучшую модель на test set\n",
        "\n",
        "В качестве разнообразия - напишите код для прогона модели на test set вы.\n",
        "\n",
        "В результате вы должны натренировать модель, которая покажет более **90%** точности на test set.  \n",
        "Как водится, лучший результат в группе получит дополнительные баллы!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EIqM1kdeh-hd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e63b8092-2c3b-439f-f898-5ecc5ab84b1e"
      },
      "source": [
        "best_model = best_run.model\n",
        "\n",
        "final_test_accuracy = compute_accuracy(best_model, test_loader)\n",
        "print(\"Final test accuracy - \", final_test_accuracy)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Final test accuracy -  0.9217117393976644\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BfH6qip6kVX_",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}